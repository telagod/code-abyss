#!/usr/bin/env python3
"""
ä»£ç è´¨é‡æ£€æŸ¥å™¨
æ£€æµ‹ä»£ç å¤æ‚åº¦ã€é‡å¤ä»£ç ã€å‘½åè§„èŒƒã€å‡½æ•°é•¿åº¦ç­‰
"""

import os
import re
import sys
import json
import ast
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Set
from enum import Enum
from collections import defaultdict


class Severity(Enum):
    ERROR = "error"
    WARNING = "warning"
    INFO = "info"


@dataclass
class Issue:
    severity: Severity
    category: str
    message: str
    file_path: str
    line_number: Optional[int] = None
    suggestion: Optional[str] = None


@dataclass
class FileMetrics:
    path: str
    lines: int = 0
    code_lines: int = 0
    comment_lines: int = 0
    blank_lines: int = 0
    functions: int = 0
    classes: int = 0
    max_complexity: int = 0
    avg_function_length: float = 0


@dataclass
class QualityResult:
    scan_path: str
    files_scanned: int = 0
    total_lines: int = 0
    total_code_lines: int = 0
    issues: List[Issue] = field(default_factory=list)
    file_metrics: List[FileMetrics] = field(default_factory=list)

    @property
    def passed(self) -> bool:
        return not any(i.severity == Severity.ERROR for i in self.issues)

    @property
    def error_count(self) -> int:
        return sum(1 for i in self.issues if i.severity == Severity.ERROR)

    @property
    def warning_count(self) -> int:
        return sum(1 for i in self.issues if i.severity == Severity.WARNING)


# è´¨é‡è§„åˆ™é…ç½®
MAX_LINE_LENGTH = 120
MAX_FUNCTION_LENGTH = 50
MAX_FILE_LENGTH = 500
MAX_COMPLEXITY = 10
MAX_PARAMETERS = 5
MIN_FUNCTION_NAME_LENGTH = 2
MAX_FUNCTION_NAME_LENGTH = 40


class PythonAnalyzer(ast.NodeVisitor):
    """Python AST åˆ†æå™¨"""

    def __init__(self, file_path: str, source: str):
        self.file_path = file_path
        self.source = source
        self.lines = source.split('\n')
        self.issues: List[Issue] = []
        self.functions: List[Dict] = []
        self.classes: List[Dict] = []
        self.complexity = 0

    def analyze(self) -> tuple[List[Issue], List[Dict], List[Dict], int]:
        try:
            tree = ast.parse(self.source)
            self.visit(tree)
        except SyntaxError as e:
            self.issues.append(Issue(
                severity=Severity.ERROR,
                category="è¯­æ³•",
                message=f"è¯­æ³•é”™è¯¯: {e.msg}",
                file_path=self.file_path,
                line_number=e.lineno
            ))
        return self.issues, self.functions, self.classes, self.complexity

    def visit_FunctionDef(self, node):
        self._analyze_function(node)
        self.generic_visit(node)

    def visit_AsyncFunctionDef(self, node):
        self._analyze_function(node)
        self.generic_visit(node)

    def visit_ClassDef(self, node):
        self.classes.append({
            "name": node.name,
            "line": node.lineno,
            "methods": len([n for n in node.body if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef))])
        })

        # æ£€æŸ¥ç±»å
        if not re.match(r'^[A-Z][a-zA-Z0-9]*$', node.name):
            self.issues.append(Issue(
                severity=Severity.WARNING,
                category="å‘½å",
                message=f"ç±»å '{node.name}' ä¸ç¬¦åˆ PascalCase è§„èŒƒ",
                file_path=self.file_path,
                line_number=node.lineno,
                suggestion="ç±»ååº”ä½¿ç”¨ PascalCaseï¼Œå¦‚ MyClassName"
            ))

        self.generic_visit(node)

    def _analyze_function(self, node):
        func_info = {
            "name": node.name,
            "line": node.lineno,
            "length": self._get_function_length(node),
            "complexity": self._calculate_complexity(node),
            "parameters": len(node.args.args)
        }
        self.functions.append(func_info)
        self.complexity = max(self.complexity, func_info["complexity"])

        # æ£€æŸ¥å‡½æ•°é•¿åº¦
        if func_info["length"] > MAX_FUNCTION_LENGTH:
            self.issues.append(Issue(
                severity=Severity.WARNING,
                category="å¤æ‚åº¦",
                message=f"å‡½æ•° '{node.name}' è¿‡é•¿ ({func_info['length']} è¡Œ > {MAX_FUNCTION_LENGTH})",
                file_path=self.file_path,
                line_number=node.lineno,
                suggestion="è€ƒè™‘æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°"
            ))

        # æ£€æŸ¥å¤æ‚åº¦
        if func_info["complexity"] > MAX_COMPLEXITY:
            self.issues.append(Issue(
                severity=Severity.WARNING,
                category="å¤æ‚åº¦",
                message=f"å‡½æ•° '{node.name}' åœˆå¤æ‚åº¦è¿‡é«˜ ({func_info['complexity']} > {MAX_COMPLEXITY})",
                file_path=self.file_path,
                line_number=node.lineno,
                suggestion="å‡å°‘åµŒå¥—å±‚çº§ï¼Œæå–å­å‡½æ•°"
            ))

        # æ£€æŸ¥å‚æ•°æ•°é‡
        if func_info["parameters"] > MAX_PARAMETERS:
            self.issues.append(Issue(
                severity=Severity.WARNING,
                category="è®¾è®¡",
                message=f"å‡½æ•° '{node.name}' å‚æ•°è¿‡å¤š ({func_info['parameters']} > {MAX_PARAMETERS})",
                file_path=self.file_path,
                line_number=node.lineno,
                suggestion="è€ƒè™‘ä½¿ç”¨é…ç½®å¯¹è±¡æˆ–æ•°æ®ç±»å°è£…å‚æ•°"
            ))

        # æ£€æŸ¥å‡½æ•°å‘½å
        if not node.name.startswith('_'):
            if not re.match(r'^[a-z][a-z0-9_]*$', node.name):
                self.issues.append(Issue(
                    severity=Severity.INFO,
                    category="å‘½å",
                    message=f"å‡½æ•°å '{node.name}' ä¸ç¬¦åˆ snake_case è§„èŒƒ",
                    file_path=self.file_path,
                    line_number=node.lineno,
                    suggestion="å‡½æ•°ååº”ä½¿ç”¨ snake_caseï¼Œå¦‚ my_function_name"
                ))

        if len(node.name) < MIN_FUNCTION_NAME_LENGTH:
            self.issues.append(Issue(
                severity=Severity.WARNING,
                category="å‘½å",
                message=f"å‡½æ•°å '{node.name}' è¿‡çŸ­",
                file_path=self.file_path,
                line_number=node.lineno,
                suggestion="ä½¿ç”¨æ›´å…·æè¿°æ€§çš„å‡½æ•°å"
            ))

    def _get_function_length(self, node) -> int:
        if hasattr(node, 'end_lineno'):
            return node.end_lineno - node.lineno + 1
        return len(ast.unparse(node).split('\n'))

    def _calculate_complexity(self, node) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦"""
        complexity = 1

        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, (ast.And, ast.Or)):
                complexity += 1
            elif isinstance(child, ast.comprehension):
                complexity += 1
                if child.ifs:
                    complexity += len(child.ifs)

        return complexity


def analyze_python_file(file_path: Path) -> tuple[FileMetrics, List[Issue]]:
    """åˆ†æ Python æ–‡ä»¶"""
    metrics = FileMetrics(path=str(file_path))
    issues = []

    try:
        content = file_path.read_text(encoding='utf-8', errors='ignore')
        lines = content.split('\n')
    except Exception as e:
        issues.append(Issue(
            severity=Severity.ERROR,
            category="æ–‡ä»¶",
            message=f"æ— æ³•è¯»å–æ–‡ä»¶: {e}",
            file_path=str(file_path)
        ))
        return metrics, issues

    # åŸºç¡€è¡Œæ•°ç»Ÿè®¡
    metrics.lines = len(lines)
    in_multiline_string = False

    for i, line in enumerate(lines, 1):
        stripped = line.strip()

        if not stripped:
            metrics.blank_lines += 1
        elif stripped.startswith('#'):
            metrics.comment_lines += 1
        elif '"""' in stripped or "'''" in stripped:
            if stripped.count('"""') == 2 or stripped.count("'''") == 2:
                metrics.comment_lines += 1
            else:
                in_multiline_string = not in_multiline_string
                metrics.comment_lines += 1
        elif in_multiline_string:
            metrics.comment_lines += 1
        else:
            metrics.code_lines += 1

        # æ£€æŸ¥è¡Œé•¿åº¦
        if len(line) > MAX_LINE_LENGTH:
            issues.append(Issue(
                severity=Severity.INFO,
                category="æ ¼å¼",
                message=f"è¡Œè¿‡é•¿ ({len(line)} > {MAX_LINE_LENGTH})",
                file_path=str(file_path),
                line_number=i
            ))

    # æ£€æŸ¥æ–‡ä»¶é•¿åº¦
    if metrics.code_lines > MAX_FILE_LENGTH:
        issues.append(Issue(
            severity=Severity.WARNING,
            category="å¤æ‚åº¦",
            message=f"æ–‡ä»¶è¿‡é•¿ ({metrics.code_lines} è¡Œä»£ç  > {MAX_FILE_LENGTH})",
            file_path=str(file_path),
            suggestion="è€ƒè™‘æ‹†åˆ†ä¸ºå¤šä¸ªæ¨¡å—"
        ))

    # AST åˆ†æ
    analyzer = PythonAnalyzer(str(file_path), content)
    ast_issues, functions, classes, complexity = analyzer.analyze()
    issues.extend(ast_issues)

    metrics.functions = len(functions)
    metrics.classes = len(classes)
    metrics.max_complexity = complexity

    if functions:
        metrics.avg_function_length = sum(f["length"] for f in functions) / len(functions)

    return metrics, issues


def analyze_generic_file(file_path: Path) -> tuple[FileMetrics, List[Issue]]:
    """åˆ†æé€šç”¨ä»£ç æ–‡ä»¶"""
    metrics = FileMetrics(path=str(file_path))
    issues = []

    try:
        content = file_path.read_text(encoding='utf-8', errors='ignore')
        lines = content.split('\n')
    except Exception:
        return metrics, issues

    metrics.lines = len(lines)

    comment_patterns = {
        '.js': '//',
        '.ts': '//',
        '.go': '//',
        '.java': '//',
        '.c': '//',
        '.cpp': '//',
        '.rs': '//',
    }

    suffix = file_path.suffix.lower()
    comment_prefix = comment_patterns.get(suffix, '//')

    for i, line in enumerate(lines, 1):
        stripped = line.strip()

        if not stripped:
            metrics.blank_lines += 1
        elif stripped.startswith(comment_prefix) or stripped.startswith('/*') or stripped.startswith('*'):
            metrics.comment_lines += 1
        else:
            metrics.code_lines += 1

        if len(line) > MAX_LINE_LENGTH:
            issues.append(Issue(
                severity=Severity.INFO,
                category="æ ¼å¼",
                message=f"è¡Œè¿‡é•¿ ({len(line)} > {MAX_LINE_LENGTH})",
                file_path=str(file_path),
                line_number=i
            ))

    if metrics.code_lines > MAX_FILE_LENGTH:
        issues.append(Issue(
            severity=Severity.WARNING,
            category="å¤æ‚åº¦",
            message=f"æ–‡ä»¶è¿‡é•¿ ({metrics.code_lines} è¡Œä»£ç  > {MAX_FILE_LENGTH})",
            file_path=str(file_path),
            suggestion="è€ƒè™‘æ‹†åˆ†ä¸ºå¤šä¸ªæ¨¡å—"
        ))

    return metrics, issues


def scan_directory(path: str, exclude_dirs: List[str] = None) -> QualityResult:
    """æ‰«æç›®å½•"""
    scan_path = Path(path).resolve()
    result = QualityResult(scan_path=str(scan_path))

    if exclude_dirs is None:
        exclude_dirs = ['.git', 'node_modules', '__pycache__', '.venv', 'venv', 'dist', 'build', '.tox']

    code_extensions = {'.py', '.js', '.ts', '.go', '.java', '.rs', '.c', '.cpp'}

    for file_path in scan_path.rglob('*'):
        if any(ex in file_path.parts for ex in exclude_dirs):
            continue

        if file_path.is_file() and file_path.suffix.lower() in code_extensions:
            result.files_scanned += 1

            if file_path.suffix.lower() == '.py':
                metrics, issues = analyze_python_file(file_path)
            else:
                metrics, issues = analyze_generic_file(file_path)

            result.file_metrics.append(metrics)
            result.issues.extend(issues)
            result.total_lines += metrics.lines
            result.total_code_lines += metrics.code_lines

    return result


def format_report(result: QualityResult, verbose: bool = False) -> str:
    """æ ¼å¼åŒ–æŠ¥å‘Š"""
    lines = []
    lines.append("=" * 60)
    lines.append("ä»£ç è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
    lines.append("=" * 60)

    lines.append(f"\næ‰«æè·¯å¾„: {result.scan_path}")
    lines.append(f"æ‰«ææ–‡ä»¶: {result.files_scanned}")
    lines.append(f"æ€»è¡Œæ•°: {result.total_lines}")
    lines.append(f"ä»£ç è¡Œæ•°: {result.total_code_lines}")
    lines.append(f"æ£€æŸ¥ç»“æœ: {'âœ“ é€šè¿‡' if result.passed else 'âœ— éœ€è¦å…³æ³¨'}")
    lines.append(f"é”™è¯¯: {result.error_count} | è­¦å‘Š: {result.warning_count}")

    if result.issues:
        lines.append("\n" + "-" * 40)
        lines.append("é—®é¢˜åˆ—è¡¨:")
        lines.append("-" * 40)

        # æŒ‰ç±»åˆ«åˆ†ç»„
        by_category = defaultdict(list)
        for issue in result.issues:
            by_category[issue.category].append(issue)

        severity_icons = {"error": "âœ—", "warning": "âš ", "info": "â„¹"}

        for category, issues in sorted(by_category.items()):
            lines.append(f"\nã€{category}ã€‘({len(issues)} ä¸ª)")
            for issue in issues[:10]:  # æ¯ç±»æœ€å¤šæ˜¾ç¤º 10 ä¸ª
                icon = severity_icons[issue.severity.value]
                loc = f":{issue.line_number}" if issue.line_number else ""
                lines.append(f"  {icon} {issue.file_path}{loc}")
                lines.append(f"    {issue.message}")
                if verbose and issue.suggestion:
                    lines.append(f"    ğŸ’¡ {issue.suggestion}")

            if len(issues) > 10:
                lines.append(f"  ... åŠå…¶ä»– {len(issues) - 10} ä¸ªé—®é¢˜")

    if verbose and result.file_metrics:
        # æ‰¾å‡ºæœ€å¤æ‚çš„æ–‡ä»¶
        complex_files = sorted(result.file_metrics, key=lambda m: m.max_complexity, reverse=True)[:5]
        if complex_files and complex_files[0].max_complexity > 0:
            lines.append("\n" + "-" * 40)
            lines.append("å¤æ‚åº¦æœ€é«˜çš„æ–‡ä»¶:")
            lines.append("-" * 40)
            for m in complex_files:
                if m.max_complexity > 0:
                    lines.append(f"  {m.path}: å¤æ‚åº¦ {m.max_complexity}, {m.functions} ä¸ªå‡½æ•°")

    lines.append("\n" + "=" * 60)
    return "\n".join(lines)


def main():
    import argparse

    parser = argparse.ArgumentParser(description="ä»£ç è´¨é‡æ£€æŸ¥å™¨")
    parser.add_argument("path", nargs="?", default=".", help="æ‰«æè·¯å¾„")
    parser.add_argument("-v", "--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    parser.add_argument("--json", action="store_true", help="JSON æ ¼å¼è¾“å‡º")

    args = parser.parse_args()

    result = scan_directory(args.path)

    if args.json:
        output = {
            "scan_path": result.scan_path,
            "files_scanned": result.files_scanned,
            "total_lines": result.total_lines,
            "total_code_lines": result.total_code_lines,
            "passed": result.passed,
            "error_count": result.error_count,
            "warning_count": result.warning_count,
            "issues": [
                {
                    "severity": i.severity.value,
                    "category": i.category,
                    "message": i.message,
                    "file_path": i.file_path,
                    "line_number": i.line_number,
                    "suggestion": i.suggestion
                }
                for i in result.issues
            ]
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
    else:
        print(format_report(result, args.verbose))

    sys.exit(0 if result.passed else 1)


if __name__ == "__main__":
    main()
